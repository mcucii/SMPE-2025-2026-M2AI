* Parallel Quicksort Project Report

** Project Overview
This document presents the performance evaluation of a custom multi-threaded QuickSort algorithm executed on multi-core machines. The core objective is to measure and analyze the speedup gained by parallelization, using statistical comparison against both sequential and standard library sorting methods across defined input sizes.

** Organization
The project is organized into three primary directories:

*** /src
This directory contains the core C code for the parallel quicksort implementation being tested. The executable generated by the build process is expected to reside here.
In order to run core C code do the following:

Compilation:
#+BEGIN_SRC bash
make -C src/
#+END_SRC

Running the code:
#+BEGIN_SRC bash
./src/parallelQuicksort [ARRAY_SIZE]
#+END_SRC

*** /test
This directory contains the Python scripts that enable experimentation under various conditions. Its contents include:
    - =run_quicksort.py=: Provides the core function to execute the C program once and parse the output times.
    - =run_experiments.py=: The main orchestration script that controls the test cycle (sizes from 300,000 to 3,000,000 with a 100,000 step), saves the data, and generates the plots.
    - =plot.py=: Contains the dedicated plotting functions that read the generated CSV and produce the performance graph.

*** /data
This directory serves as the output location for all generated results.
    - Extracted data (raw execution times) are stored in =quicksort_results.csv=.
    - The final performance visualization is stored in =quicksort_results.png=.

** Experiment Methodology
The performance evaluation follows a systematic approach:

1.  **Input Range:** Array sizes range from 300,000 to 3,000,000 elements, stepping every 100,000.
2.  **Repetitions:** Each array size is tested 30 times (=NUM_REPETITIONS=) to ensure reliable, statistically stable results.
3.  **Metrics:** Three execution times are captured for each run:
    - Sequential Quicksort Time
    - Parallel Quicksort Time
    - Built-in System Sort Time (for baseline comparison)
4.  **Analysis:**
    First, we observe the performance by manually executing the core C code a few times. We immediately notice that the built-in quicksort works the fastest, followed by the sequential implementation, and the parallel implementation is currently the slowest for these small, initial runs.

    Here are the results from these initial ad-hoc executions:
    #+BEGIN_SRC bash
./src/parallelQuicksort
Sequential quicksort took: 0.159276 sec.
Parallel quicksort took: 0.206333 sec.
Built-in quicksort took: 0.142748 sec.

./src/parallelQuicksort
Sequential quicksort took: 0.167634 sec.
Parallel quicksort took: 0.191118 sec.
Built-in quicksort took: 0.143148 sec.

./src/parallelQuicksort
Sequential quicksort took: 0.161237 sec.
Parallel quicksort took: 0.192600 sec.
Built-in quicksort took: 0.147030 sec.

    #+END_SRC

    After this initial observation, we conduct a structured experiment: for each array size, we run the quicksort implementations 30 times and calculate the average time. The resulting performance plot will be used to conclude that after a certain input size, the **parallel implementation definitely becomes the fastest**, whereas the sequential time is confirmed as the slowest due to the overhead of thread management in the parallel version being overcome by the increased work.  (check the plot, ?????)

    [[./data/mcucii_2025_15_10/quicksort_results.png]]


